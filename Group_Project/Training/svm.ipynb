{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-08-19T15:52:27.042645Z","iopub.status.busy":"2024-08-19T15:52:27.042034Z","iopub.status.idle":"2024-08-19T15:52:32.899065Z","shell.execute_reply":"2024-08-19T15:52:32.897961Z","shell.execute_reply.started":"2024-08-19T15:52:27.042613Z"},"trusted":true},"outputs":[],"source":["import os\n","import json\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import models, transforms\n","from torch.utils.data import DataLoader, Dataset\n","from PIL import Image\n","from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n","from sklearn.neighbors import NearestNeighbors\n","from sklearn.metrics import accuracy_score\n","import matplotlib.pyplot as plt\n","from joblib import dump, load\n","from sklearn.svm import SVC\n","from sklearn.model_selection import GridSearchCV"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-19T14:54:13.835917Z","iopub.status.busy":"2024-08-19T14:54:13.835322Z","iopub.status.idle":"2024-08-19T14:54:13.840591Z","shell.execute_reply":"2024-08-19T14:54:13.839719Z","shell.execute_reply.started":"2024-08-19T14:54:13.835880Z"},"trusted":true},"outputs":[],"source":["# paths to data\n","data_dir = '/kaggle/input/fashion-iq-dataset/fashionIQ_dataset'\n","image_dir = os.path.join(data_dir, 'images')\n","json_dir = os.path.join(data_dir, 'image_splits')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-19T14:54:13.842313Z","iopub.status.busy":"2024-08-19T14:54:13.841967Z","iopub.status.idle":"2024-08-19T14:54:13.854573Z","shell.execute_reply":"2024-08-19T14:54:13.853866Z","shell.execute_reply.started":"2024-08-19T14:54:13.842282Z"},"trusted":true},"outputs":[],"source":["# function to read data files\n","\n","# read data in json file\n","def read_json(file_path):\n","    with open(file_path, 'r') as f:\n","        return json.load(f)\n","\n","#  load image (path of image) from file json (follow cattegory)\n","def load_image_list(category, split):\n","    json_path = os.path.join(json_dir, f'split.{category}.{split}.json')\n","    image_list = read_json(json_path)\n","    return [os.path.join(image_dir, image_name + '.jpg') for image_name in image_list]\n","\n","# function to preprocess data\n","\n","# define transform for preprocess step\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","# define class FashionIQDataset \n","class FashionIQDataset(Dataset):\n","    def __init__(self, image_paths, labels, transform=None):\n","        self.image_paths = image_paths\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        image_path = self.image_paths[idx]\n","        image = Image.open(image_path).convert('RGB')\n","        label = self.labels[idx]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-19T14:54:13.856998Z","iopub.status.busy":"2024-08-19T14:54:13.856736Z","iopub.status.idle":"2024-08-19T14:54:14.110926Z","shell.execute_reply":"2024-08-19T14:54:14.110014Z","shell.execute_reply.started":"2024-08-19T14:54:13.856975Z"},"trusted":true},"outputs":[],"source":["# load and split data in corresponding set \n","\n","# load images follow their category in three set: train, val and test\n","# category - dress\n","train_images_dress = load_image_list('dress', 'train')\n","val_images_dress = load_image_list('dress', 'val')\n","test_images_dress = load_image_list('dress', 'test')\n","\n","# category - shirt\n","train_images_shirt = load_image_list('shirt', 'train')\n","val_images_shirt = load_image_list('shirt', 'val')\n","test_images_shirt = load_image_list('shirt', 'test')\n","\n","# category - top&tee\n","train_images_toptee = load_image_list('toptee', 'train')\n","val_images_toptee = load_image_list('toptee', 'val')\n","test_images_toptee = load_image_list('toptee', 'test')\n","\n","# combine all image (in each set) to make a dataset\n","train_images = train_images_dress + train_images_shirt + train_images_toptee\n","val_images = val_images_dress + val_images_shirt + val_images_toptee\n","test_images = test_images_dress + test_images_shirt + test_images_toptee\n","\n","# label for images (0: dress, 1: shirt, 2: toptee)\n","train_labels = [0] * len(train_images_dress) + [1] * len(train_images_shirt) + [2] * len(train_images_toptee)\n","val_labels = [0] * len(val_images_dress) + [1] * len(val_images_shirt) + [2] * len(val_images_toptee)\n","test_labels = [0] * len(test_images_dress) + [1] * len(test_images_shirt) + [2] * len(test_images_toptee)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-19T14:54:14.112380Z","iopub.status.busy":"2024-08-19T14:54:14.112094Z","iopub.status.idle":"2024-08-19T14:54:14.118410Z","shell.execute_reply":"2024-08-19T14:54:14.117344Z","shell.execute_reply.started":"2024-08-19T14:54:14.112355Z"},"trusted":true},"outputs":[],"source":["# pre-process data\n","train_dataset = FashionIQDataset(train_images, train_labels, transform=transform)\n","val_dataset = FashionIQDataset(val_images, val_labels, transform=transform)\n","test_dataset = FashionIQDataset(test_images, test_labels, transform=transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-19T14:54:14.119808Z","iopub.status.busy":"2024-08-19T14:54:14.119492Z","iopub.status.idle":"2024-08-19T14:54:15.873558Z","shell.execute_reply":"2024-08-19T14:54:15.872595Z","shell.execute_reply.started":"2024-08-19T14:54:14.119785Z"},"trusted":true},"outputs":[],"source":["# if device is GPU \n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model_dir = '/kaggle/input/resnet50-weight-fashion/best_model.pth'\n","num_classes = 3\n","\n","# init resnet50 model as the way training\n","model = models.resnet50(weights=None)  # pretrained=False vì bạn sẽ tải trọng số của mình\n","model.fc = nn.Linear(model.fc.in_features, num_classes)\n","\n","# load \n","# model.load_state_dict(torch.load(model_dir))\n","model.load_state_dict(torch.load(model_dir))\n","\n","model.to(device)  \n","# Chuyển mô hình về chế độ đánh giá (evaluation mode)\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-19T14:54:15.874979Z","iopub.status.busy":"2024-08-19T14:54:15.874695Z","iopub.status.idle":"2024-08-19T14:54:15.888065Z","shell.execute_reply":"2024-08-19T14:54:15.887069Z","shell.execute_reply.started":"2024-08-19T14:54:15.874954Z"},"trusted":true},"outputs":[],"source":["def extract_features_batchwise(loader, model, device, save_path_features, save_path_labels):\n","    model.eval()\n","    features_list = []\n","    labels_list = []\n","    \n","    os.makedirs(os.path.dirname(save_path_features), exist_ok=True)\n","    os.makedirs(os.path.dirname(save_path_labels), exist_ok=True)\n","    \n","    with torch.no_grad():\n","        for batch_idx, (images, labels) in enumerate(loader):\n","            images = images.to(device)\n","            output = model(images)\n","            output = output.view(output.size(0), -1)\n","            features_list.append(output.cpu().numpy())\n","            labels_list.append(labels.numpy())\n","            \n","            # save feature in batch to save resource\n","            if batch_idx % 20 == 0:  # save after 10 batch\n","                batch_features = np.concatenate(features_list, axis=0)\n","                batch_labels = np.concatenate(labels_list, axis=0)\n","                np.save(f'{save_path_features}_batch_{batch_idx}.npy', batch_features, allow_pickle=False)\n","                np.save(f'{save_path_labels}_batch_{batch_idx}.npy', batch_labels, allow_pickle=False)\n","                features_list = []\n","                labels_list = []\n","            \n","    if features_list:\n","        batch_features = np.concatenate(features_list, axis=0)\n","        batch_labels = np.concatenate(labels_list, axis=0)\n","        np.save(f'{save_path_features}_final.npy', batch_features, allow_pickle=False)\n","        np.save(f'{save_path_labels}_final.npy', batch_labels, allow_pickle=False)\n","        \n","        \n","def merge_npy_files(folder_path, file_pattern, output_file):\n","    sorted_files = sorted(\n","    [f for f in os.listdir(folder_path) if f.startswith(file_pattern + '_batch') and f.endswith('.npy')],\n","    key=lambda x: int(x.split('_')[-1].split('.')[0])\n",")\n","    sorted_files.append(file_pattern + '_final.npy')\n","    arrays = [np.load(os.path.join(folder_path, f)) for f in sorted_files]\n","    \n","    all_array = np.concatenate(arrays, axis=0)\n","    np.save(output_file, all_array, allow_pickle=False)\n","    print(f\"Saved combined features to {output_file}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-19T15:52:32.901222Z","iopub.status.busy":"2024-08-19T15:52:32.900762Z","iopub.status.idle":"2024-08-19T15:52:33.210465Z","shell.execute_reply":"2024-08-19T15:52:33.208924Z","shell.execute_reply.started":"2024-08-19T15:52:32.901194Z"},"trusted":true},"outputs":[],"source":["save_path_features = '/kaggle/working/features/features/'\n","save_path_labels = '/kaggle/working/features/labels/'\n","\n","extract_features_batchwise(train_loader, model, device,save_path_features + 'train/features', save_path_labels + 'train/labels')\n","extract_features_batchwise(val_loader, model, device,save_path_features + 'valid/features', save_path_labels + 'valid/labels')\n","extract_features_batchwise(test_loader, model, device,save_path_features + 'test/features', save_path_labels + 'test/labels')\n","\n","merge_npy_files('/kaggle/working/features/labels/train', 'labels', '/kaggle/working/features/train_labels.npy')\n","merge_npy_files('/kaggle/working/features/features/train', 'features', '/kaggle/working/features/train_features.npy')\n","\n","merge_npy_files('/kaggle/working/features/labels/valid', 'labels', '/kaggle/working/features/val_labels.npy')\n","merge_npy_files('/kaggle/working/features/features/valid', 'features', '/kaggle/working/features/val_features.npy')\n","\n","merge_npy_files('/kaggle/working/features/labels/test', 'labels', '/kaggle/working/features/test_labels.npy')\n","merge_npy_files('/kaggle/working/features/features/test', 'features', '/kaggle/working/features/test_features.npy')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-19T15:53:14.601212Z","iopub.status.busy":"2024-08-19T15:53:14.600792Z","iopub.status.idle":"2024-08-19T15:53:14.611476Z","shell.execute_reply":"2024-08-19T15:53:14.610351Z","shell.execute_reply.started":"2024-08-19T15:53:14.601180Z"},"trusted":true},"outputs":[],"source":["X_train = np.load('/kaggle/input/features-and-labels-fashioniq/train_features.npy')\n","y_train = np.load('/kaggle/input/features-and-labels-fashioniq/train_labels.npy')\n","\n","X_valid = np.load('/kaggle/input/features-and-labels-fashioniq/val_features.npy')\n","y_valid = np.load('/kaggle/input/features-and-labels-fashioniq/val_labels.npy')\n","\n","X_test = np.load('/kaggle/input/features-and-labels-fashioniq/test_features.npy')\n","y_test = np.load('/kaggle/input/features-and-labels-fashioniq/test_labels.npy')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-19T15:53:16.248095Z","iopub.status.busy":"2024-08-19T15:53:16.247235Z","iopub.status.idle":"2024-08-19T20:29:43.233778Z","shell.execute_reply":"2024-08-19T20:29:43.232506Z","shell.execute_reply.started":"2024-08-19T15:53:16.248054Z"},"trusted":true},"outputs":[],"source":["\n","\n","# sử dụng để tìm kiếm siêu tham số tốt nhất cho mô hình\n","param_grid = {\n","    'C': [0.1, 1, 10],\n","    'kernel': ['linear', 'rbf', 'poly'],\n","    'gamma': ['scale', 'auto']  # Chỉ áp dụng cho kernel phi tuyến\n","}\n","\n","svm = SVC()\n","\n","grid_search = GridSearchCV(svm, param_grid, cv=5, scoring = 'accuracy')\n","\n","# Huấn luyện mô hình với train set và tinh chỉnh với validation set\n","print(\"Training data\")\n","grid_search.fit(X_train, y_train)\n","\n","# Kết quả hyperparameters tốt nhất\n","print(\"Best Parameters: \", grid_search.best_params_)\n","\n","# Đánh giá trên validation set \n","val_accuracy = grid_search.score(X_valid, y_valid)\n","print(\"Validation Accuracy: \", val_accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-19T20:37:19.786623Z","iopub.status.busy":"2024-08-19T20:37:19.785920Z","iopub.status.idle":"2024-08-19T20:37:19.796120Z","shell.execute_reply":"2024-08-19T20:37:19.795097Z","shell.execute_reply.started":"2024-08-19T20:37:19.786582Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","\n","# Kết quả của GridSearchCV\n","print(\"Best Parameters: \", grid_search.best_params_)\n","print(\"Best Score: \", grid_search.best_score_)\n","print(\"Best Estimator: \", grid_search.best_estimator_)\n","\n","# Xem thông tin về tất cả các kết quả trong GridSearch\n","results = grid_search.cv_results_\n","for mean_score, params in zip(results['mean_test_score'], results['params']):\n","    print(f\"Mean Score: {mean_score:.3f} with parameters: {params}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-19T20:29:43.255228Z","iopub.status.busy":"2024-08-19T20:29:43.254632Z","iopub.status.idle":"2024-08-19T20:29:43.267932Z","shell.execute_reply":"2024-08-19T20:29:43.266798Z","shell.execute_reply.started":"2024-08-19T20:29:43.255201Z"},"trusted":true},"outputs":[],"source":["# lưu trọng số đã huấn luyện\n","dump(grid_search, '/kaggle/working/svm_model.joblib')"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5514624,"sourceId":9133170,"sourceType":"datasetVersion"},{"datasetId":5517663,"sourceId":9136627,"sourceType":"datasetVersion"},{"datasetId":5565363,"sourceId":9204607,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
